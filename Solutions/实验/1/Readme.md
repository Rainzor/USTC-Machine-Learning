## py文件

### \_\_init\_\_
#### 参数
penalty[默认为l2]：正则化范数

gamma[默认为0]：正则化程度

fit\_intercept[默认为True]：是否匹配斜率

#### 功能
新建类并记录学习器属性。

#### 返回
无。

***

### sigmoid
#### 参数
x：需要计算Sigmoid函数值的向量

#### 功能
计算学习器中的w[此处可能包含扩展的截距]与x产生的Sigmoid函数结果。

#### 返回
计算出的值。

***

### count_loss
#### 参数
X：训练集中的样本

y：样本对应的结果

#### 功能
按照相应正则化方式计算学习器中的w对训练集产生的损失。

#### 返回
计算出的损失。

***

### count_grad_loss
#### 参数
X：训练集中的样本

y：样本对应的结果

#### 功能
按照相应正则化方式计算训练集上产生的损失对w的梯度。

#### 返回
计算出的损失梯度向量。

***

### fit
#### 参数
X：训练集中的样本

y：样本对应的结果

lr[默认为0.01]：学习率

tol[默认为1e-4]：允许的最大梯度

max\_iter[默认为1e3]：最大迭代次数

#### 功能
根据fit\_intercept确定是否增广模型，并利用训练集学习。

#### 返回
每次迭代计算出的损失形成的向量。

***

### predict
#### 参数
X: 测试集中的样本。

#### 功能
生成预测结果。

#### 返回
对测试集生成的预测结果。

***

## ipynb文件
### Data Cleaning
清除了离散属性缺失的样本，对连续属性以均值替代。

### Encode
对离散属性进行最小0最大1的编码。

### Data Process
将所有属性归一化并随机打乱，区分出7:3的训练集、测试集。

### Train

以给定参数进行训练。

### Test
画出训练时的损失曲线，预测并对比正确率。